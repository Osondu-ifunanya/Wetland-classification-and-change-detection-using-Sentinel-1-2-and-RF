{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOETsFhAOz59sqimMQc7NJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Osondu-ifunanya/Wetland-classification-and-change-detection-using-Sentinel-1-2-and-RF/blob/main/WetlandClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEzEUv5DCM2_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --------------------------\n",
        "# 1) PARAMETERS / SETTINGS\n",
        "# --------------------------\n",
        "np.random.seed(42)\n",
        "GRID_H, GRID_W = 80, 80          # spatial grid size (pixels)\n",
        "N_PIXELS = GRID_H * GRID_W\n",
        "\n",
        "# fraction of wetlands initially\n",
        "WETLAND_COVER = 0.20\n",
        "\n",
        "# fraction of wetland pixels that change (gain or loss) by T2\n",
        "CHANGE_RATE = 0.10\n",
        "\n",
        "# --------------------------\n",
        "# 2) SYNTHETIC SENTINEL-1 GENERATION\n",
        "# --------------------------\n",
        "def generate_sar_field(h, w, vv_mean, vh_mean, vv_std=0.5, vh_std=0.3, speckle_scale=0.1):\n",
        "    \"\"\"Generate synthetic SAR backscatter fields (linear scale) with speckle-like noise.\"\"\"\n",
        "    vv = np.random.normal(vv_mean, vv_std, size=(h, w))\n",
        "    vh = np.random.normal(vh_mean, vh_std, size=(h, w))\n",
        "    # multiplicative speckle noise\n",
        "    speckle_vv = np.random.gamma(shape=1/speckle_scale, scale=speckle_scale, size=(h, w))\n",
        "    speckle_vh = np.random.gamma(shape=1/speckle_scale, scale=speckle_scale, size=(h, w))\n",
        "    vv = vv * speckle_vv\n",
        "    vh = vh * speckle_vh\n",
        "    # clip to realistic SAR linear-range positive values\n",
        "    vv = np.clip(vv, 1e-3, None)\n",
        "    vh = np.clip(vh, 1e-3, None)\n",
        "    return vv, vh\n",
        "\n",
        "# Create base landcover mask: 1 = wetland, 0 = non-wetland\n",
        "base_mask = np.zeros((GRID_H, GRID_W), dtype=int)\n",
        "n_wet = int(WETLAND_COVER * N_PIXELS)\n",
        "wet_indices = np.random.choice(N_PIXELS, size=n_wet, replace=False)\n",
        "base_mask.flat[wet_indices] = 1\n",
        "\n",
        "# Generate SAR at T1\n",
        "# Assume wetlands have lower VV (water absorption) and different VH behavior\n",
        "vv_t1, vh_t1 = generate_sar_field(GRID_H, GRID_W,\n",
        "                                  vv_mean=np.where(base_mask==1, 2.5, 4.5),\n",
        "                                  vh_mean=np.where(base_mask==1, 0.9, 1.6),\n",
        "                                  vv_std=0.3, vh_std=0.15, speckle_scale=0.08)\n",
        "\n",
        "# Create T2 landcover by applying random changes\n",
        "t2_mask = base_mask.copy()\n",
        "n_change = int(CHANGE_RATE * N_PIXELS)\n",
        "change_indices = np.random.choice(N_PIXELS, size=n_change, replace=False)\n",
        "# flip some pixels: wet->non-wet or non-wet->wet with 50/50\n",
        "for idx in change_indices:\n",
        "    if np.random.rand() < 0.5:\n",
        "        t2_mask.flat[idx] = 1 - t2_mask.flat[idx]  # toggle\n",
        "\n",
        "# Generate SAR at T2 using t2_mask-dependent stats\n",
        "vv_t2, vh_t2 = generate_sar_field(GRID_H, GRID_W,\n",
        "                                  vv_mean=np.where(t2_mask==1, 2.7, 4.3),\n",
        "                                  vh_mean=np.where(t2_mask==1, 0.95, 1.55),\n",
        "                                  vv_std=0.35, vh_std=0.16, speckle_scale=0.09)\n",
        "\n",
        "# --------------------------\n",
        "# 3) FEATURE ENGINEERING\n",
        "# --------------------------\n",
        "# Use log10(dB-like) transforms commonly used with SAR (just for synthetic realism)\n",
        "def to_db(x):\n",
        "    # ensure positive\n",
        "    return 10.0 * np.log10(np.clip(x, 1e-6, None))\n",
        "\n",
        "vv_t1_db = to_db(vv_t1); vh_t1_db = to_db(vh_t1)\n",
        "vv_t2_db = to_db(vv_t2); vh_t2_db = to_db(vh_t2)\n",
        "\n",
        "# Ratio and difference features (VV/VH, VV-VH, temporal difference)\n",
        "eps = 1e-6\n",
        "vv_vh_ratio_t1 = vv_t1 / (vh_t1 + eps)\n",
        "vv_vh_ratio_t2 = vv_t2 / (vh_t2 + eps)\n",
        "vv_minus_vh_t1 = vv_t1_db - vh_t1_db\n",
        "vv_minus_vh_t2 = vv_t2_db - vh_t2_db\n",
        "\n",
        "# Temporal changes\n",
        "delta_vv_db = vv_t2_db - vv_t1_db\n",
        "delta_vh_db = vh_t2_db - vh_t1_db\n",
        "delta_ratio = vv_vh_ratio_t2 - vv_vh_ratio_t1\n",
        "delta_vv_minus_vh = vv_minus_vh_t2 - vv_minus_vh_t1\n",
        "\n",
        "# Stack feature arrays into per-pixel rows\n",
        "features_t1 = np.stack([\n",
        "    vv_t1_db.flatten(),\n",
        "    vh_t1_db.flatten(),\n",
        "    np.log1p(vv_vh_ratio_t1.flatten()),\n",
        "    vv_minus_vh_t1.flatten()\n",
        "], axis=1)\n",
        "\n",
        "features_t2 = np.stack([\n",
        "    vv_t2_db.flatten(),\n",
        "    vh_t2_db.flatten(),\n",
        "    np.log1p(vv_vh_ratio_t2.flatten()),\n",
        "    vv_minus_vh_t2.flatten()\n",
        "], axis=1)\n",
        "\n",
        "features_delta = np.stack([\n",
        "    delta_vv_db.flatten(),\n",
        "    delta_vh_db.flatten(),\n",
        "    np.log1p(np.abs(delta_ratio.flatten())+eps),\n",
        "    delta_vv_minus_vh.flatten()\n",
        "], axis=1)\n",
        "\n",
        "# Ground truth labels per pixel\n",
        "y_t1 = base_mask.flatten()\n",
        "y_t2 = t2_mask.flatten()\n",
        "\n",
        "# --------------------------\n",
        "# 4) CLASSIFICATION (Random Forest)\n",
        "# --------------------------\n",
        "# Train RF on T1 features to classify wetlands at T1\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_t1, y_t1, test_size=0.25, random_state=0, stratify=y_t1)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=0, min_samples_leaf=5)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_test_pred = rf.predict(X_test)\n",
        "print(\"T1 Classification Report (on test subset):\")\n",
        "print(classification_report(y_test, y_test_pred, digits=3))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Predict full maps at T1 and T2\n",
        "pred_t1 = rf.predict(features_t1).reshape(GRID_H, GRID_W)\n",
        "pred_t2 = rf.predict(features_t2).reshape(GRID_H, GRID_W)\n",
        "\n",
        "# --------------------------\n",
        "# 5) CHANGE DETECTION\n",
        "# --------------------------\n",
        "# Simple rule: changed where predicted class differs between T1 and T2\n",
        "change_map_pred = (pred_t1 != pred_t2).astype(int)\n",
        "change_map_true = (base_mask != t2_mask).astype(int)\n",
        "\n",
        "# --------------------------\n",
        "# 6) EVALUATION\n",
        "# --------------------------\n",
        "print(\"\\nConfusion matrix for T1 (test subset):\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "# Evaluate change detection (pixel-wise)\n",
        "print(\"\\nChange detection evaluation (pixel-wise):\")\n",
        "print(\"True change fraction:\", change_map_true.mean())\n",
        "print(\"Predicted change fraction:\", change_map_pred.mean())\n",
        "print(\"Change detection classification report (predicted vs true):\")\n",
        "print(classification_report(change_map_true.flatten(), change_map_pred.flatten(), digits=3))\n",
        "\n",
        "# --------------------------\n",
        "# 7) VISUALIZATIONS\n",
        "# --------------------------\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.subplot(3,3,1); plt.title(\"VV T1 (dB)\"); plt.imshow(vv_t1_db, cmap='viridis'); plt.colorbar()\n",
        "plt.subplot(3,3,2); plt.title(\"VH T1 (dB)\"); plt.imshow(vh_t1_db, cmap='viridis'); plt.colorbar()\n",
        "plt.subplot(3,3,3); plt.title(\"VV/VH ratio T1 (log)\"); plt.imshow(np.log1p(vv_vh_ratio_t1), cmap='magma'); plt.colorbar()\n",
        "\n",
        "plt.subplot(3,3,4); plt.title(\"True Wetland T1\"); plt.imshow(base_mask, cmap='Blues'); plt.colorbar()\n",
        "plt.subplot(3,3,5); plt.title(\"Predicted Wetland T1\"); plt.imshow(pred_t1, cmap='Blues'); plt.colorbar()\n",
        "plt.subplot(3,3,6); plt.title(\"Predicted Wetland T2\"); plt.imshow(pred_t2, cmap='Blues'); plt.colorbar()\n",
        "\n",
        "plt.subplot(3,3,7); plt.title(\"True Change (T1→T2)\"); plt.imshow(change_map_true, cmap='Reds'); plt.colorbar()\n",
        "plt.subplot(3,3,8); plt.title(\"Predicted Change (T1→T2)\"); plt.imshow(change_map_pred, cmap='Reds'); plt.colorbar()\n",
        "plt.subplot(3,3,9); plt.title(\"Delta VV dB (T2-T1)\"); plt.imshow(delta_vv_db, cmap='coolwarm'); plt.colorbar()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --------------------------\n",
        "# 8) EXPORT RESULTS TO EXCEL (per-pixel)\n",
        "# --------------------------\n",
        "df_export = pd.DataFrame({\n",
        "    'pixel_id': np.arange(N_PIXELS),\n",
        "    'row': np.repeat(np.arange(GRID_H), GRID_W),\n",
        "    'col': np.tile(np.arange(GRID_W), GRID_H),\n",
        "    'VV_T1_dB': vv_t1_db.flatten(),\n",
        "    'VH_T1_dB': vh_t1_db.flatten(),\n",
        "    'VV_T2_dB': vv_t2_db.flatten(),\n",
        "    'VH_T2_dB': vh_t2_db.flatten(),\n",
        "    'VVVH_ratio_T1_log': np.log1p(vv_vh_ratio_t1.flatten()),\n",
        "    'VVVH_ratio_T2_log': np.log1p(vv_vh_ratio_t2.flatten()),\n",
        "    'delta_VV_dB': delta_vv_db.flatten(),\n",
        "    'delta_VH_dB': delta_vh_db.flatten(),\n",
        "    'true_wetland_T1': y_t1,\n",
        "    'true_wetland_T2': y_t2,\n",
        "    'pred_wetland_T1': rf.predict(features_t1),\n",
        "    'pred_wetland_T2': rf.predict(features_t2),\n",
        "    'true_change': change_map_true.flatten(),\n",
        "    'pred_change': change_map_pred.flatten()\n",
        "})\n",
        "\n",
        "excel_path = \"synthetic_s1_wetland_change_detection.xlsx\"\n",
        "df_export.to_excel(excel_path, index=False)\n",
        "print(f\"\\nExported per-pixel results to: {excel_path}\")\n",
        "\n",
        "# --------------------------\n",
        "# 9) FEATURE IMPORTANCE\n",
        "# --------------------------\n",
        "feat_names = ['VV_dB', 'VH_dB', 'log(VV/VH)', 'VV_minus_VH_dB']\n",
        "fi = rf.feature_importances_\n",
        "fi_df = pd.DataFrame({'feature': feat_names, 'importance': fi}).sort_values('importance', ascending=False)\n",
        "print(\"\\nFeature importances (RF for T1):\")\n",
        "print(fi_df)\n"
      ]
    }
  ]
}